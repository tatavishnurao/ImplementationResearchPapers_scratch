{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be38ce04-f41d-45df-87bb-0065e5e6be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4363564-0dab-43ee-9e0a-01783e2c7ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6e6dfd-e67c-49b8-845c-514dc53c49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef73206-aacf-4615-b731-8fb0513f8ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch 1, Loss: 1.83369\n",
      "Epoch 2, Loss: 1.38304\n",
      "Epoch 3, Loss: 1.18825\n",
      "Epoch 4, Loss: 1.05272\n",
      "Epoch 5, Loss: 0.95422\n",
      "Epoch 6, Loss: 0.87802\n",
      "Epoch 7, Loss: 0.81494\n",
      "Epoch 8, Loss: 0.76167\n",
      "Epoch 9, Loss: 0.70961\n",
      "Epoch 10, Loss: 0.66679\n",
      "Epoch 11, Loss: 0.61977\n",
      "Epoch 12, Loss: 0.58467\n",
      "Epoch 13, Loss: 0.55185\n",
      "Epoch 14, Loss: 0.51767\n",
      "Epoch 15, Loss: 0.49361\n",
      "Epoch 16, Loss: 0.46282\n",
      "Epoch 17, Loss: 0.42838\n",
      "Epoch 18, Loss: 0.41261\n",
      "Epoch 19, Loss: 0.38855\n",
      "Epoch 20, Loss: 0.37747\n",
      "Epoch 21, Loss: 0.35553\n",
      "Epoch 22, Loss: 0.34023\n",
      "Epoch 23, Loss: 0.33111\n",
      "Epoch 24, Loss: 0.31030\n",
      "Epoch 25, Loss: 0.30319\n",
      "Epoch 26, Loss: 0.29153\n",
      "Epoch 27, Loss: 0.28127\n",
      "Epoch 28, Loss: 0.27428\n",
      "Epoch 29, Loss: 0.26384\n",
      "Epoch 30, Loss: 0.25871\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNet()\n",
    "net.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.004, momentum=0.9)\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.5f}')\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(net.state_dict(), 'trained_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33686a0-f614-4564-921e-26cc5a2cd9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 66.80 %\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet()\n",
    "model.load_state_dict(torch.load('trained_net.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba9d3aec-bfee-44ff-a0b0-820c7b626b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: dog\n",
      "Prediction: truck\n"
     ]
    }
   ],
   "source": [
    "def load_image(image_path):\n",
    "    new_transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "image_paths = ['dog.jpg', 'plane.jpg']\n",
    "images = [load_image(img) for img in image_paths]\n",
    "\n",
    "inference_model = NeuralNet()\n",
    "inference_model.load_state_dict(torch.load('trained_net.pth'))\n",
    "inference_model.to(device)\n",
    "inference_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image in images:\n",
    "        image = image.to(device)\n",
    "        output = inference_model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        print(f'Prediction: {class_names[predicted.item()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bdbb31-b6ec-4fdb-a178-ac1a259d26ce",
   "metadata": {},
   "source": [
    "#### Now I don't much about model's accuracy at this point of time but capping at 64-65% was just not great\n",
    "#### So, from the readme file and also from the paper I decided to experiment with actually coding the model's dropout approach where we just randomly turn off some % of neurons for each training step \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fde667b-027c-48b5-b2c8-bb745b79c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolutional Block 1\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        # Convolutional Block 2\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Block 2\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Classifier\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49226a73-57e3-4b5e-9727-967da9c24ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.63031\n",
      "Epoch 2, Loss: 1.26508\n",
      "Epoch 3, Loss: 1.10129\n",
      "Epoch 4, Loss: 0.99242\n",
      "Epoch 5, Loss: 0.92116\n",
      "Epoch 6, Loss: 0.85828\n",
      "Epoch 7, Loss: 0.79886\n",
      "Epoch 8, Loss: 0.75841\n",
      "Epoch 9, Loss: 0.71423\n",
      "Epoch 10, Loss: 0.66879\n",
      "Epoch 11, Loss: 0.63871\n",
      "Epoch 12, Loss: 0.60094\n",
      "Epoch 13, Loss: 0.56967\n",
      "Epoch 14, Loss: 0.54176\n",
      "Epoch 15, Loss: 0.51398\n",
      "Epoch 16, Loss: 0.48930\n",
      "Epoch 17, Loss: 0.46251\n",
      "Epoch 18, Loss: 0.43769\n",
      "Epoch 19, Loss: 0.41592\n",
      "Epoch 20, Loss: 0.39153\n",
      "Epoch 21, Loss: 0.38179\n",
      "Epoch 22, Loss: 0.36041\n",
      "Epoch 23, Loss: 0.34923\n",
      "Epoch 24, Loss: 0.33744\n",
      "Epoch 25, Loss: 0.32577\n",
      "Epoch 26, Loss: 0.31280\n",
      "Epoch 27, Loss: 0.30061\n",
      "Epoch 28, Loss: 0.29185\n",
      "Epoch 29, Loss: 0.28603\n",
      "Epoch 30, Loss: 0.27280\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Use the new model\n",
    "net = ImprovedNet()\n",
    "net.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# You can also try the Adam optimizer, which often works well\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Add the scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "\n",
    "# In your training loop, after the optimizer.step(), add:\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.5f}')\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(net.state_dict(), 'trained_net1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ccf932-764b-410b-807a-9584b32e5c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 84.45 %\n"
     ]
    }
   ],
   "source": [
    "model = ImprovedNet()\n",
    "model.load_state_dict(torch.load('trained_net1.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c21104-300c-4e99-8b8a-326e84127115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: dog\n",
      "Prediction: plane\n"
     ]
    }
   ],
   "source": [
    "def load_image(image_path):\n",
    "    new_transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "image_paths = ['dog.jpg', 'plane.jpg']\n",
    "images = [load_image(img) for img in image_paths]\n",
    "\n",
    "inference_model1 = ImprovedNet()\n",
    "inference_model1.load_state_dict(torch.load('trained_net1.pth'))\n",
    "inference_model1.to(device)\n",
    "inference_model1.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image in images:\n",
    "        image = image.to(device)\n",
    "        output = inference_model1(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        print(f'Prediction: {class_names[predicted.item()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45013eec-3cca-46c6-b179-0cae1567bcf2",
   "metadata": {},
   "source": [
    "#### I did want to stop here but I just had to try with data augmentation as well to check the accuracy spikes with both approaches mentioned in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d70d254c-617c-4c70-b150-7bf315bfe49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8df79f12-eb6c-4968-a4cb-1869a7c1637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a50b2c8b-9e46-4c12-a054-7778f77122a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch 1, Loss: 1.80733\n",
      "Epoch 2, Loss: 1.49310\n",
      "Epoch 3, Loss: 1.33670\n",
      "Epoch 4, Loss: 1.21884\n",
      "Epoch 5, Loss: 1.14128\n",
      "Epoch 6, Loss: 1.08649\n",
      "Epoch 7, Loss: 1.03787\n",
      "Epoch 8, Loss: 0.99637\n",
      "Epoch 9, Loss: 0.96265\n",
      "Epoch 10, Loss: 0.92655\n",
      "Epoch 11, Loss: 0.89566\n",
      "Epoch 12, Loss: 0.86057\n",
      "Epoch 13, Loss: 0.83356\n",
      "Epoch 14, Loss: 0.80085\n",
      "Epoch 15, Loss: 0.77272\n",
      "Epoch 16, Loss: 0.74948\n",
      "Epoch 17, Loss: 0.73220\n",
      "Epoch 18, Loss: 0.69859\n",
      "Epoch 19, Loss: 0.68718\n",
      "Epoch 20, Loss: 0.66461\n",
      "Epoch 21, Loss: 0.64334\n",
      "Epoch 22, Loss: 0.62850\n",
      "Epoch 23, Loss: 0.61598\n",
      "Epoch 24, Loss: 0.59902\n",
      "Epoch 25, Loss: 0.58596\n",
      "Epoch 26, Loss: 0.53337\n",
      "Epoch 27, Loss: 0.51406\n",
      "Epoch 28, Loss: 0.50838\n",
      "Epoch 29, Loss: 0.49951\n",
      "Epoch 30, Loss: 0.49824\n",
      "Epoch 31, Loss: 0.48926\n",
      "Epoch 32, Loss: 0.48556\n",
      "Epoch 33, Loss: 0.48357\n",
      "Epoch 34, Loss: 0.48435\n",
      "Epoch 35, Loss: 0.47747\n",
      "Epoch 36, Loss: 0.47202\n",
      "Epoch 37, Loss: 0.47217\n",
      "Epoch 38, Loss: 0.46571\n",
      "Epoch 39, Loss: 0.46945\n",
      "Epoch 40, Loss: 0.46203\n",
      "Epoch 41, Loss: 0.45559\n",
      "Epoch 42, Loss: 0.45173\n",
      "Epoch 43, Loss: 0.45388\n",
      "Epoch 44, Loss: 0.44491\n",
      "Epoch 45, Loss: 0.44771\n",
      "Epoch 46, Loss: 0.44867\n",
      "Epoch 47, Loss: 0.44118\n",
      "Epoch 48, Loss: 0.44041\n",
      "Epoch 49, Loss: 0.44075\n",
      "Epoch 50, Loss: 0.43770\n",
      "Epoch 51, Loss: 0.42951\n",
      "Epoch 52, Loss: 0.42895\n",
      "Epoch 53, Loss: 0.42647\n",
      "Epoch 54, Loss: 0.42630\n",
      "Epoch 55, Loss: 0.42629\n",
      "Epoch 56, Loss: 0.42728\n",
      "Epoch 57, Loss: 0.42596\n",
      "Epoch 58, Loss: 0.42704\n",
      "Epoch 59, Loss: 0.42823\n",
      "Epoch 60, Loss: 0.41881\n",
      "Epoch 61, Loss: 0.42550\n",
      "Epoch 62, Loss: 0.42141\n",
      "Epoch 63, Loss: 0.42244\n",
      "Epoch 64, Loss: 0.42641\n",
      "Epoch 65, Loss: 0.42236\n",
      "Epoch 66, Loss: 0.42262\n",
      "Epoch 67, Loss: 0.42752\n",
      "Epoch 68, Loss: 0.42566\n",
      "Epoch 69, Loss: 0.42255\n",
      "Epoch 70, Loss: 0.42326\n",
      "Epoch 71, Loss: 0.42071\n",
      "Epoch 72, Loss: 0.42256\n",
      "Epoch 73, Loss: 0.41931\n",
      "Epoch 74, Loss: 0.42530\n",
      "Epoch 75, Loss: 0.42083\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net2 = ImprovedNet2()\n",
    "net2.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net2.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "for epoch in range(75):\n",
    "    running_loss = 0.0\n",
    "    net2.train()\n",
    "    \n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net2(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.5f}')\n",
    "    scheduler.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2425f9b9-1b88-416d-9eba-ed44468f7bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 86.96 %\n"
     ]
    }
   ],
   "source": [
    "net2.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net2(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695e3f1-394b-48f9-8390-93820020e46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents (UV)",
   "language": "python",
   "name": "agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
